{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCwGMHW0eL2-"
      },
      "source": [
        "# SVM Image Classification - Garbage Dataset\n",
        "\n",
        "This notebook implements Support Vector Machine (SVM) classification on the garbage dataset from Kaggle. We'll process the image data and apply SVM with different kernels for classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl0zB9fPeL3C",
        "outputId": "0c5f1497-cc01-4775-b8a9-c4ad5d4c43e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install opendatasets scikit-learn matplotlib seaborn numpy pandas pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyr5bnj2eL3D",
        "outputId": "619f7abf-e507-470b-be1a-59e59281c0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import opendatasets as od\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P8kI_fieL3E"
      },
      "source": [
        "## Dataset Download and Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9j2zPMQeL3F",
        "outputId": "ae66bd9d-7a67-46d8-de8b-fd37b87c2079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: bumithaekanayake\n",
            "Your Kaggle Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Dataset URL: https://www.kaggle.com/datasets/zlatan599/garbage-dataset-classification\n",
            "Downloading garbage-dataset-classification.zip to ./garbage-dataset-classification\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121M/121M [00:00<00:00, 1.06GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the garbage classification dataset from Kaggle\n",
        "dataset_url = \"https://www.kaggle.com/datasets/zlatan599/garbage-dataset-classification\"\n",
        "od.download(dataset_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIiV8RRWeL3G"
      },
      "source": [
        "**Note for Google Colab users**: If you encounter authentication issues when downloading the dataset, you may need to:\n",
        "\n",
        "1. Go to your Kaggle account â†’ Account â†’ API â†’ Create New API Token\n",
        "2. Download the `kaggle.json` file\n",
        "3. Upload it to Colab when prompted, or run:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K907ZefaeL3I",
        "outputId": "dad87030-9b85-4052-df38-b7eebf79dc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset directory: ./garbage-dataset-classification/Garbage_Dataset_Classification/images/\n",
            "\n",
            "Directory contents:\n",
            "ðŸ“ glass/\n",
            "   Contains 2500 items\n",
            "   - glass_03245.jpg\n",
            "   - glass_02661.jpg\n",
            "   - glass_00833.jpg\n",
            "   - glass_00960.jpg\n",
            "   - glass_03149.jpg\n",
            "   ... and 2495 more items\n",
            "ðŸ“ paper/\n",
            "   Contains 2315 items\n",
            "   - paper_02086.jpg\n",
            "   - paper_02643.jpg\n",
            "   - paper_02011.jpg\n",
            "   - paper_02352.jpg\n",
            "   - paper_01373.jpg\n",
            "   ... and 2310 more items\n",
            "ðŸ“ trash/\n",
            "   Contains 2500 items\n",
            "   - trash_12702.jpg\n",
            "   - trash_19143.jpg\n",
            "   - trash_13674.jpg\n",
            "   - trash_11007.jpg\n",
            "   - trash_07523.jpg\n",
            "   ... and 2495 more items\n",
            "ðŸ“ plastic/\n",
            "   Contains 2288 items\n",
            "   - plastic_01588.jpg\n",
            "   - plastic_02534.jpg\n",
            "   - plastic_02422.jpg\n",
            "   - plastic_01650.jpg\n",
            "   - plastic_01485.jpg\n",
            "   ... and 2283 more items\n",
            "ðŸ“ cardboard/\n",
            "   Contains 2214 items\n",
            "   - cardboard_02624.jpg\n",
            "   - cardboard_02562.jpg\n",
            "   - cardboard_01421.jpg\n",
            "   - cardboard_00521.jpg\n",
            "   - cardboard_02370.jpg\n",
            "   ... and 2209 more items\n",
            "ðŸ“ metal/\n",
            "   Contains 2084 items\n",
            "   - metal_01565.jpg\n",
            "   - metal_01640.jpg\n",
            "   - metal_02251.jpg\n",
            "   - metal_02023.jpg\n",
            "   - metal_02095.jpg\n",
            "   ... and 2079 more items\n"
          ]
        }
      ],
      "source": [
        "# Explore the dataset structure\n",
        "data_dir = \"./garbage-dataset-classification/Garbage_Dataset_Classification/images/\"\n",
        "print(\"Dataset directory:\", data_dir)\n",
        "print(\"\\nDirectory contents:\")\n",
        "for item in os.listdir(data_dir):\n",
        "    item_path = os.path.join(data_dir, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        print(f\"ðŸ“ {item}/\")\n",
        "        subdir_contents = os.listdir(item_path)\n",
        "        print(f\"   Contains {len(subdir_contents)} items\")\n",
        "        if len(subdir_contents) <= 10:\n",
        "            for subitem in subdir_contents[:5]:\n",
        "                print(f\"   - {subitem}\")\n",
        "        else:\n",
        "            for subitem in subdir_contents[:5]:\n",
        "                print(f\"   - {subitem}\")\n",
        "            print(f\"   ... and {len(subdir_contents) - 5} more items\")\n",
        "    else:\n",
        "        print(f\"ðŸ“„ {item}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wulp_LHueL3J"
      },
      "source": [
        "## Image Preprocessing for SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ImNF6meL3J",
        "outputId": "2653fd35-56b8-4e0d-d133-0ffbae36864d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing images...\n",
            "Found 6 classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
            "Processing class 'cardboard' with 2214 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cardboard: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:01<00:00, 283.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class 'glass' with 2500 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading glass: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:01<00:00, 309.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class 'metal' with 2084 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading metal: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 688.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class 'paper' with 2315 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading paper: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 659.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class 'plastic' with 2288 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading plastic: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 690.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class 'trash' with 2500 images...\n",
            "  Limited to 500 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading trash: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 697.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset loaded successfully!\n",
            "Total samples: 3000\n",
            "Feature dimension: 12288\n",
            "Number of classes: 6\n",
            "Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
          ]
        }
      ],
      "source": [
        "def load_and_preprocess_images(data_dir, target_size=(64, 64), max_samples_per_class=1000):\n",
        "    \"\"\"\n",
        "    Load and preprocess images for SVM classification\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to the dataset directory\n",
        "        target_size: Target size for resizing images (width, height)\n",
        "        max_samples_per_class: Maximum number of samples per class to avoid memory issues\n",
        "\n",
        "    Returns:\n",
        "        X: Flattened image features\n",
        "        y: Class labels\n",
        "        class_names: List of class names\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    class_names = []\n",
        "\n",
        "    # Get all subdirectories (classes)\n",
        "    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    subdirs.sort()  # Sort for consistent ordering\n",
        "\n",
        "    print(f\"Found {len(subdirs)} classes: {subdirs}\")\n",
        "\n",
        "    for class_idx, class_name in enumerate(subdirs):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        image_files = glob.glob(os.path.join(class_path, \"*.jpg\")) + glob.glob(os.path.join(class_path, \"*.png\"))\n",
        "\n",
        "        print(f\"Processing class '{class_name}' with {len(image_files)} images...\")\n",
        "\n",
        "        # Limit samples per class to avoid memory issues\n",
        "        if len(image_files) > max_samples_per_class:\n",
        "            image_files = image_files[:max_samples_per_class]\n",
        "            print(f\"  Limited to {max_samples_per_class} samples\")\n",
        "\n",
        "        class_names.append(class_name)\n",
        "\n",
        "        for img_path in tqdm(image_files, desc=f\"Loading {class_name}\"):\n",
        "            try:\n",
        "                # Load and resize image\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                img = img.resize(target_size)\n",
        "\n",
        "                # Convert to numpy array and normalize\n",
        "                img_array = np.array(img) / 255.0\n",
        "\n",
        "                # Flatten the image\n",
        "                img_flattened = img_array.flatten()\n",
        "\n",
        "                X.append(img_flattened)\n",
        "                y.append(class_idx)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return np.array(X), np.array(y), class_names\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "print(\"Loading and preprocessing images...\")\n",
        "X, y, class_names = load_and_preprocess_images(data_dir, target_size=(64, 64), max_samples_per_class=500)\n",
        "\n",
        "print(f\"\\nDataset loaded successfully!\")\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Feature dimension: {X.shape[1]}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wwjj3XCeL3L",
        "outputId": "b604e60c-c18c-47a0-b68f-24b0079db574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying PCA for dimensionality reduction...\n",
            "Components needed for 90% variance: 118\n",
            "Components needed for 95% variance: 311\n",
            "Reduced feature dimension from 12288 to 311\n",
            "Explained variance ratio: 0.9495\n"
          ]
        }
      ],
      "source": [
        "# Apply PCA for dimensionality reduction (optional but recommended for SVM)\n",
        "print(\"Applying PCA for dimensionality reduction...\")\n",
        "\n",
        "# First, let's see how much variance we can retain with different numbers of components\n",
        "pca_full = PCA()\n",
        "pca_full.fit(X)\n",
        "\n",
        "# Calculate cumulative explained variance\n",
        "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "\n",
        "# Find number of components for 95% variance\n",
        "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "n_components_90 = np.argmax(cumulative_variance >= 0.90) + 1\n",
        "\n",
        "print(f\"Components needed for 90% variance: {n_components_90}\")\n",
        "print(f\"Components needed for 95% variance: {n_components_95}\")\n",
        "\n",
        "# Apply PCA with 95% variance retention\n",
        "n_components = min(n_components_95, 1000)  # Cap at 1000 components for computational efficiency\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "print(f\"Reduced feature dimension from {X.shape[1]} to {X_pca.shape[1]}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# Use PCA-transformed features\n",
        "X_final = X_pca\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G2bWjsfeL3M",
        "outputId": "68a5e051-002c-47d5-fbcf-b477e1bc0a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (2400, 311)\n",
            "Test set size: (600, 311)\n",
            "Number of classes: 6\n",
            "Class distribution in training set: [400 400 400 400 400 400]\n",
            "Class distribution in test set: [100 100 100 100 100 100]\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set size: {X_train_scaled.shape}\")\n",
        "print(f\"Test set size: {X_test_scaled.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "print(f\"Class distribution in training set: {np.bincount(y_train)}\")\n",
        "print(f\"Class distribution in test set: {np.bincount(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_1vOO57eL3N"
      },
      "source": [
        "## SVM Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJQ4RuaveL3N",
        "outputId": "88587067-5bff-45dc-a813-e1073f81767e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SVM models with different kernels...\n",
            "\n",
            "Training SVM with linear kernel...\n",
            "Accuracy with linear kernel: 0.3217\n",
            "\n",
            "Training SVM with rbf kernel...\n",
            "Accuracy with rbf kernel: 0.3983\n",
            "\n",
            "Training SVM with poly kernel...\n",
            "Accuracy with poly kernel: 0.2050\n",
            "\n",
            "==================================================\n",
            "SVM PERFORMANCE SUMMARY\n",
            "==================================================\n",
            "LINEAR Kernel: 0.3217\n",
            "RBF Kernel: 0.3983\n",
            "POLY Kernel: 0.2050\n"
          ]
        }
      ],
      "source": [
        "# Train SVM with different kernels\n",
        "def train_svm_model(X_train, y_train, kernel='rbf', C=1.0, gamma='scale',degree=3):\n",
        "    \"\"\"\n",
        "    Train SVM model with specified parameters\n",
        "    \"\"\"\n",
        "    svm_model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    return svm_model\n",
        "\n",
        "# Test different SVM kernels\n",
        "kernels = ['linear', 'rbf', 'poly']\n",
        "svm_models = {}\n",
        "results = {}\n",
        "\n",
        "print(\"Training SVM models with different kernels...\")\n",
        "\n",
        "for kernel in kernels:\n",
        "    print(f\"\\nTraining SVM with {kernel} kernel...\")\n",
        "\n",
        "    if kernel == 'linear':\n",
        "        model = train_svm_model(X_train_scaled, y_train, kernel='linear', C=1.0)\n",
        "    elif kernel == 'rbf':\n",
        "        model = train_svm_model(X_train_scaled, y_train, kernel='rbf', C=1.0, gamma='scale')\n",
        "    elif kernel == 'poly':\n",
        "        model = train_svm_model(X_train_scaled, y_train, kernel='poly', C=1.0, gamma='scale', degree=3)\n",
        "\n",
        "    svm_models[kernel] = model\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[kernel] = {\n",
        "        'model': model,\n",
        "        'predictions': y_pred,\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy with {kernel} kernel: {accuracy:.4f}\")\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SVM PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "for kernel, result in results.items():\n",
        "    print(f\"{kernel.upper()} Kernel: {result['accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW1JsSAUeL3O",
        "outputId": "e950031e-7005-4646-f738-06d18868d9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing hyperparameter tuning...\n",
            "Best performing kernel: rbf\n",
            "Tuning hyperparameters for rbf kernel...\n",
            "Best parameters: {'C': 1, 'gamma': 'scale'}\n",
            "Best cross-validation score: 0.3779\n",
            "Final test accuracy: 0.3983\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter tuning for the best performing kernel\n",
        "print(\"Performing hyperparameter tuning...\")\n",
        "\n",
        "# Find the best kernel\n",
        "best_kernel = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
        "print(f\"Best performing kernel: {best_kernel}\")\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "if best_kernel == 'linear':\n",
        "    param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "elif best_kernel == 'rbf':\n",
        "    param_grid = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]}\n",
        "elif best_kernel == 'poly':\n",
        "    param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'degree': [2, 3, 4]}\n",
        "\n",
        "# Perform grid search\n",
        "print(f\"Tuning hyperparameters for {best_kernel} kernel...\")\n",
        "grid_search = GridSearchCV(\n",
        "    SVC(kernel=best_kernel, random_state=42),\n",
        "    param_grid,\n",
        "    cv=3,  # Use 3-fold CV for faster computation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "\n",
        "print(f\"Final test accuracy: {best_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n"
      ],
      "metadata": {
        "id": "mswkEn6llLMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFUUqmjteL3P"
      },
      "source": [
        "## Results Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAveobiReL3Q"
      },
      "outputs": [],
      "source": [
        "# Visualize results safely (for tabular or image data)\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# 1. Accuracy comparison\n",
        "plt.subplot(2, 3, 1)\n",
        "kernels = list(results.keys())\n",
        "accuracies = [results[k]['accuracy'] for k in kernels]\n",
        "bars = plt.bar(kernels, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "plt.title('SVM Accuracy by Kernel')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# 2. Confusion Matrix for best model\n",
        "plt.subplot(2, 3, 2)\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f'Confusion Matrix ({best_kernel.upper()} Kernel)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# 3. Classification Report\n",
        "plt.subplot(2, 3, 3)\n",
        "report = classification_report(y_test, y_pred_best, output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).iloc[:-1, :-2].T  # Exclude support and avg\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.3f')\n",
        "plt.title('Classification Metrics')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "\n",
        "# 4. Feature importance (only for linear kernel)\n",
        "if best_kernel == 'linear':\n",
        "    plt.subplot(2, 3, 4)\n",
        "    feature_importance = np.abs(best_model.coef_[0])\n",
        "    top_features = np.argsort(feature_importance)[-20:]\n",
        "    plt.barh(range(len(top_features)), feature_importance[top_features])\n",
        "    plt.title('Top 20 Feature Importances (Linear SVM)')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Feature Index')\n",
        "\n",
        "# 5. Cross-validation scores\n",
        "plt.subplot(2, 3, 5)\n",
        "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5)\n",
        "plt.boxplot([cv_scores], labels=[f'{best_kernel.upper()} SVM'])\n",
        "plt.title('Cross-Validation Scores')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.text(1, np.mean(cv_scores), f'Mean: {np.mean(cv_scores):.3f}',\n",
        "         ha='center', va='bottom')\n",
        "\n",
        "# 6. Sample predictions visualization (works for tabular data)\n",
        "plt.subplot(2, 3, 6)\n",
        "sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
        "sample_true = y_test[sample_indices]\n",
        "sample_pred = y_pred_best[sample_indices]\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'True Label': sample_true,\n",
        "    'Predicted Label': sample_pred\n",
        "})\n",
        "sns.heatmap(pd.crosstab(comparison_df['True Label'], comparison_df['Predicted Label']),\n",
        "            annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('Sample Predictions Overview')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxfbKzLceL3R"
      },
      "source": [
        "## Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnfyrhXdeL3R"
      },
      "source": [
        "## Model Comparison with Other Algorithms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzt55wgveL3S",
        "outputId": "0a99252a-fb9f-4300-8471-4d5bb9c479c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating multiple models...\n",
            "============================================================\n",
            "\n",
            "Training SVM (Linear)...\n",
            "  Accuracy: 0.3217\n",
            "  Training time: 29.30s\n",
            "  Prediction time: 0.16s\n",
            "\n",
            "Training SVM (RBF)...\n",
            "  Accuracy: 0.3983\n",
            "  Training time: 1.77s\n",
            "  Prediction time: 0.73s\n",
            "\n",
            "Training SVM (Polynomial)...\n",
            "  Accuracy: 0.2050\n",
            "  Training time: 2.08s\n",
            "  Prediction time: 0.25s\n",
            "\n",
            "============================================================\n",
            "MODEL COMPARISON SUMMARY\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Define models for comparison\n",
        "import time # Import the time module\n",
        "\n",
        "models = {\n",
        "    'SVM (Linear)': SVC(kernel='linear', C=1.0, random_state=42),\n",
        "    'SVM (RBF)': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42),\n",
        "    'SVM (Polynomial)': SVC(kernel='poly', C=1.0, gamma='scale', degree=3, random_state=42),\n",
        "}\n",
        "\n",
        "# Train and evaluate all models\n",
        "model_results = {}\n",
        "training_times = {}\n",
        "prediction_times = {}\n",
        "\n",
        "print(\"Training and evaluating multiple models...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    model_results[name] = {\n",
        "        'model': model,\n",
        "        'predictions': y_pred,\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "    training_times[name] = training_time\n",
        "    prediction_times[name] = prediction_time\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Prediction time: {prediction_time:.2f}s\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPRy-m-geL3T",
        "outputId": "6b407713-ff6e-4980-b741-073f9ddb5570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANKED MODEL PERFORMANCE:\n",
            "============================================================\n",
            "           Model  Accuracy  Training Time (s)  Prediction Time (s)\n",
            "       SVM (RBF)    0.3983             1.7681               0.7326\n",
            "    SVM (Linear)    0.3217            29.2969               0.1646\n",
            "SVM (Polynomial)    0.2050             2.0830               0.2534\n",
            "\n",
            "ðŸ† BEST PERFORMING MODEL: SVM (RBF)\n",
            "   Accuracy: 0.3983\n",
            "   Training Time: 1.77s\n",
            "   Prediction Time: 0.73s\n",
            "\n",
            "ðŸ“Š PERFORMANCE INSIGHTS:\n",
            "   â€¢ Accuracy Range: 0.2050 - 0.3983\n",
            "   â€¢ Fastest Training: SVM (RBF)\n",
            "   â€¢ Fastest Prediction: SVM (Linear)\n",
            "   â€¢ Most Balanced: SVM (RBF)\n"
          ]
        }
      ],
      "source": [
        "# Create comprehensive comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(model_results.keys()),\n",
        "    'Accuracy': [model_results[name]['accuracy'] for name in model_results.keys()],\n",
        "    'Training Time (s)': [training_times[name] for name in model_results.keys()],\n",
        "    'Prediction Time (s)': [prediction_times[name] for name in model_results.keys()]\n",
        "})\n",
        "\n",
        "# Sort by accuracy (descending)\n",
        "comparison_df = comparison_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"RANKED MODEL PERFORMANCE:\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
        "\n",
        "# Find best model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
        "\n",
        "print(f\"\\nðŸ† BEST PERFORMING MODEL: {best_model_name}\")\n",
        "print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"   Training Time: {comparison_df.iloc[0]['Training Time (s)']:.2f}s\")\n",
        "print(f\"   Prediction Time: {comparison_df.iloc[0]['Prediction Time (s)']:.2f}s\")\n",
        "\n",
        "# Performance insights\n",
        "print(f\"\\nðŸ“Š PERFORMANCE INSIGHTS:\")\n",
        "print(f\"   â€¢ Accuracy Range: {comparison_df['Accuracy'].min():.4f} - {comparison_df['Accuracy'].max():.4f}\")\n",
        "print(f\"   â€¢ Fastest Training: {comparison_df.loc[comparison_df['Training Time (s)'].idxmin(), 'Model']}\")\n",
        "print(f\"   â€¢ Fastest Prediction: {comparison_df.loc[comparison_df['Prediction Time (s)'].idxmin(), 'Model']}\")\n",
        "print(f\"   â€¢ Most Balanced: {comparison_df.loc[(comparison_df['Accuracy'] * 0.8 + (1/comparison_df['Training Time (s)']) * 0.2).idxmax(), 'Model']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCZ_SxfzeL3U"
      },
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "# 1. Accuracy Comparison\n",
        "plt.subplot(2, 4, 1)\n",
        "model_names = comparison_df['Model']\n",
        "accuracies = comparison_df['Accuracy']\n",
        "bars = plt.bar(range(len(model_names)), accuracies, color=plt.cm.viridis(np.linspace(0, 1, len(model_names))))\n",
        "plt.title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45, ha='right')\n",
        "plt.ylim(0, 1)\n",
        "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 2. Training Time Comparison\n",
        "plt.subplot(2, 4, 2)\n",
        "training_times_list = comparison_df['Training Time (s)']\n",
        "bars = plt.bar(range(len(model_names)), training_times_list, color=plt.cm.plasma(np.linspace(0, 1, len(model_names))))\n",
        "plt.title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45, ha='right')\n",
        "for i, (bar, time_val) in enumerate(zip(bars, training_times_list)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(training_times_list)*0.01,\n",
        "             f'{time_val:.1f}s', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 3. Prediction Time Comparison\n",
        "plt.subplot(2, 4, 3)\n",
        "pred_times_list = comparison_df['Prediction Time (s)']\n",
        "bars = plt.bar(range(len(model_names)), pred_times_list, color=plt.cm.inferno(np.linspace(0, 1, len(model_names))))\n",
        "plt.title('Prediction Time Comparison', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45, ha='right')\n",
        "for i, (bar, time_val) in enumerate(zip(bars, pred_times_list)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(pred_times_list)*0.01,\n",
        "             f'{time_val:.3f}s', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 4. Accuracy vs Training Time Scatter\n",
        "plt.subplot(2, 4, 4)\n",
        "plt.scatter(training_times_list, accuracies, s=100, alpha=0.7, c=range(len(model_names)), cmap='tab10')\n",
        "for i, name in enumerate(model_names):\n",
        "    plt.annotate(name, (training_times_list.iloc[i], accuracies.iloc[i]),\n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "plt.xlabel('Training Time (s)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Training Time', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Top 5 Models Performance\n",
        "plt.subplot(2, 4, 5)\n",
        "top_5 = comparison_df.head(5)\n",
        "bars = plt.bar(range(len(top_5)), top_5['Accuracy'], color=plt.cm.Set3(np.linspace(0, 1, len(top_5))))\n",
        "plt.title('Top 5 Models by Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(range(len(top_5)), top_5['Model'], rotation=45, ha='right')\n",
        "plt.ylim(0, 1)\n",
        "for i, (bar, acc) in enumerate(zip(bars, top_5['Accuracy'])):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# 6. Model Categories Performance\n",
        "plt.subplot(2, 4, 6)\n",
        "svm_models = comparison_df[comparison_df['Model'].str.contains('SVM')]\n",
        "ensemble_models = comparison_df[comparison_df['Model'].str.contains('Forest|Boosting')]\n",
        "other_models = comparison_df[~comparison_df['Model'].str.contains('SVM|Forest|Boosting')]\n",
        "\n",
        "categories = ['SVM Models', 'Ensemble Models', 'Other Models']\n",
        "category_accuracies = [\n",
        "    svm_models['Accuracy'].mean(),\n",
        "    ensemble_models['Accuracy'].mean(),\n",
        "    other_models['Accuracy'].mean()\n",
        "]\n",
        "\n",
        "bars = plt.bar(categories, category_accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "plt.title('Performance by Model Category', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Average Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for bar, acc in zip(bars, category_accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 7. Confusion Matrix for Best Model\n",
        "plt.subplot(2, 4, 7)\n",
        "best_model_predictions = model_results[best_model_name]['predictions']\n",
        "cm = confusion_matrix(y_test, best_model_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(f'Best Model Confusion Matrix\\n({best_model_name})', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# 8. Performance Summary Table\n",
        "plt.subplot(2, 4, 8)\n",
        "plt.axis('off')\n",
        "table_data = comparison_df.head(8)[['Model', 'Accuracy']].values\n",
        "table = plt.table(cellText=table_data,\n",
        "                  colLabels=['Model', 'Accuracy'],\n",
        "                  cellLoc='center',\n",
        "                  loc='center',\n",
        "                  colWidths=[0.6, 0.3])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(8)\n",
        "table.scale(1, 2)\n",
        "plt.title('Top 8 Models Summary', fontsize=12, fontweight='bold', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSMWVxPseL3V",
        "outputId": "e344c097-34b6-4730-b1be-28526b940677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DETAILED ANALYSIS OF TOP PERFORMING MODELS\n",
            "======================================================================\n",
            "\n",
            "ðŸ† RANK #1: SVM (RBF)\n",
            "   Accuracy: 0.3983\n",
            "   Training Time: 1.77s\n",
            "   Prediction Time: 0.73s\n",
            "   Per-class Performance:\n",
            "     cardboard: P=0.380, R=0.350, F1=0.365\n",
            "     glass: P=0.352, R=0.250, F1=0.292\n",
            "     metal: P=0.480, R=0.470, F1=0.475\n",
            "     paper: P=0.449, R=0.310, F1=0.367\n",
            "     plastic: P=0.381, R=0.510, F1=0.436\n",
            "     trash: P=0.368, R=0.500, F1=0.424\n",
            "\n",
            "ðŸ† RANK #2: SVM (Linear)\n",
            "   Accuracy: 0.3217\n",
            "   Training Time: 29.30s\n",
            "   Prediction Time: 0.16s\n",
            "   Per-class Performance:\n",
            "     cardboard: P=0.312, R=0.390, F1=0.347\n",
            "     glass: P=0.277, R=0.360, F1=0.313\n",
            "     metal: P=0.367, R=0.360, F1=0.364\n",
            "     paper: P=0.354, R=0.290, F1=0.319\n",
            "     plastic: P=0.279, R=0.290, F1=0.284\n",
            "     trash: P=0.393, R=0.240, F1=0.298\n",
            "\n",
            "ðŸ† RANK #3: SVM (Polynomial)\n",
            "   Accuracy: 0.2050\n",
            "   Training Time: 2.08s\n",
            "   Prediction Time: 0.25s\n",
            "   Per-class Performance:\n",
            "     cardboard: P=0.833, R=0.050, F1=0.094\n",
            "     glass: P=1.000, R=0.060, F1=0.113\n",
            "     metal: P=0.818, R=0.090, F1=0.162\n",
            "     paper: P=1.000, R=0.030, F1=0.058\n",
            "     plastic: P=0.174, R=1.000, F1=0.297\n",
            "     trash: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "ðŸ’¡ MODEL RECOMMENDATIONS:\n",
            "==================================================\n",
            "ðŸŽ¯ For Maximum Accuracy: SVM (RBF)\n",
            "âš¡ For Fastest Training: SVM (RBF)\n",
            "ðŸš€ For Fastest Prediction: SVM (Linear)\n",
            "âš–ï¸  For Balanced Performance: SVM (RBF)\n",
            "ðŸ”¬ Best SVM Kernel: SVM (RBF) (Overall Rank: #1)\n",
            "\n",
            "ðŸ“ˆ PERFORMANCE INSIGHTS:\n",
            "   â€¢ Accuracy improvement over worst model: 94.3%\n",
            "   â€¢ Training time range: 1.77s - 29.30s\n",
            "   â€¢ Prediction time range: 0.165s - 0.733s\n",
            "   â€¢ Models with >80% accuracy: 0\n",
            "   â€¢ Models with <1s training time: 0\n"
          ]
        }
      ],
      "source": [
        "# Detailed analysis of best performing models\n",
        "print(\"=\"*70)\n",
        "print(\"DETAILED ANALYSIS OF TOP PERFORMING MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get top 3 models\n",
        "top_3_models = comparison_df.head(3)\n",
        "\n",
        "for idx, row in top_3_models.iterrows():\n",
        "    model_name = row['Model']\n",
        "    print(f\"\\nðŸ† RANK #{idx+1}: {model_name}\")\n",
        "    print(f\"   Accuracy: {row['Accuracy']:.4f}\")\n",
        "    print(f\"   Training Time: {row['Training Time (s)']:.2f}s\")\n",
        "    print(f\"   Prediction Time: {row['Prediction Time (s)']:.2f}s\")\n",
        "\n",
        "    # Get detailed classification report for top 3\n",
        "    predictions = model_results[model_name]['predictions']\n",
        "    report = classification_report(y_test, predictions, target_names=class_names, output_dict=True)\n",
        "\n",
        "    print(f\"   Per-class Performance:\")\n",
        "    for class_name in class_names:\n",
        "        if class_name in report:\n",
        "            precision = report[class_name]['precision']\n",
        "            recall = report[class_name]['recall']\n",
        "            f1 = report[class_name]['f1-score']\n",
        "            print(f\"     {class_name}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "# Model recommendations\n",
        "print(f\"\\nðŸ’¡ MODEL RECOMMENDATIONS:\")\n",
        "print(f\"=\"*50)\n",
        "\n",
        "# Best overall accuracy\n",
        "best_accuracy_model = comparison_df.iloc[0]['Model']\n",
        "print(f\"ðŸŽ¯ For Maximum Accuracy: {best_accuracy_model}\")\n",
        "\n",
        "# Fastest training\n",
        "fastest_training = comparison_df.loc[comparison_df['Training Time (s)'].idxmin(), 'Model']\n",
        "print(f\"âš¡ For Fastest Training: {fastest_training}\")\n",
        "\n",
        "# Fastest prediction\n",
        "fastest_prediction = comparison_df.loc[comparison_df['Prediction Time (s)'].idxmin(), 'Model']\n",
        "print(f\"ðŸš€ For Fastest Prediction: {fastest_prediction}\")\n",
        "\n",
        "# Most balanced (good accuracy + reasonable speed)\n",
        "balanced_score = comparison_df['Accuracy'] * 0.7 + (1 / comparison_df['Training Time (s)']) * 0.3\n",
        "most_balanced = comparison_df.loc[balanced_score.idxmax(), 'Model']\n",
        "print(f\"âš–ï¸  For Balanced Performance: {most_balanced}\")\n",
        "\n",
        "# SVM specific analysis\n",
        "svm_performance = comparison_df[comparison_df['Model'].str.contains('SVM')]\n",
        "if len(svm_performance) > 0:\n",
        "    best_svm = svm_performance.iloc[0]['Model']\n",
        "    svm_rank = comparison_df[comparison_df['Model'] == best_svm].index[0] + 1\n",
        "    print(f\"ðŸ”¬ Best SVM Kernel: {best_svm} (Overall Rank: #{svm_rank})\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ PERFORMANCE INSIGHTS:\")\n",
        "print(f\"   â€¢ Accuracy improvement over worst model: {((comparison_df.iloc[0]['Accuracy'] - comparison_df.iloc[-1]['Accuracy']) / comparison_df.iloc[-1]['Accuracy'] * 100):.1f}%\")\n",
        "print(f\"   â€¢ Training time range: {comparison_df['Training Time (s)'].min():.2f}s - {comparison_df['Training Time (s)'].max():.2f}s\")\n",
        "print(f\"   â€¢ Prediction time range: {comparison_df['Prediction Time (s)'].min():.3f}s - {comparison_df['Prediction Time (s)'].max():.3f}s\")\n",
        "print(f\"   â€¢ Models with >80% accuracy: {len(comparison_df[comparison_df['Accuracy'] > 0.8])}\")\n",
        "print(f\"   â€¢ Models with <1s training time: {len(comparison_df[comparison_df['Training Time (s)'] < 1.0])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlsuyyLFeL3W"
      },
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*70)\n",
        "print(\"SVM IMAGE CLASSIFICATION - FINAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"Dataset: Garbage Classification Dataset\")\n",
        "print(f\"Total samples processed: {len(X)}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Classes: {', '.join(class_names)}\")\n",
        "print(f\"Original feature dimension: {X.shape[1]}\")\n",
        "print(f\"PCA reduced dimension: {X_final.shape[1]}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "print(f\"\\nSVM Performance Comparison:\")\n",
        "for kernel, result in results.items():\n",
        "    print(f\"  {kernel.upper()} Kernel: {result['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nBest Model:\")\n",
        "print(f\"  Kernel: {best_kernel.upper()}\")\n",
        "print(f\"  Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"  Cross-validation Score: {grid_search.best_score_:.4f}\")\n",
        "print(f\"  Test Accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nKey Insights:\")\n",
        "print(f\"  1. PCA dimensionality reduction helped reduce computational complexity\")\n",
        "print(f\"  2. Feature standardization improved SVM performance\")\n",
        "print(f\"  3. Hyperparameter tuning optimized the model performance\")\n",
        "print(f\"  4. The {best_kernel} kernel performed best for this dataset\")\n",
        "\n",
        "print(f\"\\nRecommendations for Improvement:\")\n",
        "print(f\"  1. Try different image preprocessing techniques (edge detection, texture features)\")\n",
        "print(f\"  2. Experiment with different feature extraction methods (HOG, LBP)\")\n",
        "print(f\"  3. Consider ensemble methods combining multiple SVM models\")\n",
        "print(f\"  4. Use more sophisticated data augmentation techniques\")\n",
        "print(f\"  5. Try deep learning approaches for comparison\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}